{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099867b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\ldz11\\.cache\\modelscope\\hub\\models\\iic\\speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 18:57:27,962 - modelscope - WARNING - Model revision not specified, use revision: v2.0.5\n",
      "2025-03-20 18:57:29,663 - modelscope - INFO - Use user-specified model revision: v2.0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\ldz11\\.cache\\modelscope\\hub\\models\\iic\\speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 18:57:31,403 - modelscope - INFO - Use user-specified model revision: v2.0.5\n",
      "2025-03-20 18:57:31,839 - modelscope - INFO - initiate model from C:\\Users\\ldz11\\.cache\\modelscope\\hub\\models\\iic\\speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n",
      "2025-03-20 18:57:31,840 - modelscope - INFO - initiate model from location C:\\Users\\ldz11\\.cache\\modelscope\\hub\\models\\iic\\speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch.\n",
      "2025-03-20 18:57:31,846 - modelscope - INFO - initialize model from C:\\Users\\ldz11\\.cache\\modelscope\\hub\\models\\iic\\speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n",
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\ldz11\\.cache\\modelscope\\hub\\models\\iic\\speech_fsmn_vad_zh-cn-16k-common-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 18:58:15,282 - modelscope - WARNING - Model revision not specified, use revision: v2.0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\ldz11\\.cache\\modelscope\\hub\\models\\iic\\punc_ct-transformer_cn-en-common-vocab471067-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 18:58:17,135 - modelscope - WARNING - Model revision not specified, use revision: v2.0.4\n",
      "2025-03-20 18:58:39,221 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2025-03-20 18:58:39,222 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2025-03-20 18:58:39,222 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\ldz11\\\\.cache\\\\modelscope\\\\hub\\\\models\\\\iic\\\\speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch'}. trying to build by task and model information.\n",
      "2025-03-20 18:58:39,223 - modelscope - WARNING - No preprocessor key ('funasr', 'auto-speech-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2025-03-20 18:58:39,228 - modelscope - INFO - cuda is not available, using cpu instead.\n",
      "\n",
      "\n",
      "  0%|\u001b[34m                                                                                            \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[A\n",
      "\n",
      "100%|\u001b[34m████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:00<00:00,  4.37it/s]\u001b[0m\u001b[A\u001b[A\n",
      "\n",
      "{'load_data': '0.005', 'extract_feat': '0.036', 'forward': '0.229', 'batch_size': '1', 'rtf': '0.004'}, : 100%|\u001b[34m█\u001b[0m| 1/1 [\u001b[0m\u001b[A\u001b[A\n",
      "\n",
      "rtf_avg: 0.004: 100%|\u001b[34m████████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:00<00:00,  4.24it/s]\u001b[0m\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|\u001b[31m                                                                                            \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|\u001b[34m                                                                                            \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|\u001b[34m████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:00<00:00,  2.15it/s]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "{'load_data': '0.000', 'extract_feat': '0.005', 'forward': '0.466', 'batch_size': '1', 'rtf': '0.058'}, : 100%|\u001b[34m█\u001b[0m| 1/1 [\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "rtf_avg: 0.058: 100%|\u001b[34m████████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:00<00:00,  2.12it/s]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|\u001b[34m                                                                                            \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|\u001b[34m████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:00<00:00,  1.21it/s]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "{'load_data': '0.000', 'extract_feat': '0.010', 'forward': '0.827', 'batch_size': '1', 'rtf': '0.043'}, : 100%|\u001b[34m█\u001b[0m| 1/1 [\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "rtf_avg: 0.043: 100%|\u001b[34m████████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:00<00:00,  1.20it/s]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|\u001b[34m                                                                                            \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|\u001b[34m████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:01<00:00,  1.08s/it]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "{'load_data': '0.000', 'extract_feat': '0.015', 'forward': '1.085', 'batch_size': '1', 'rtf': '0.046'}, : 100%|\u001b[34m█\u001b[0m| 1/1 [\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "rtf_avg: 0.046: 100%|\u001b[34m████████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:01<00:00,  1.09s/it]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|\u001b[34m                                                                                            \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|\u001b[34m████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:00<00:00,  5.44it/s]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.183', 'batch_size': '1', 'rtf': '-0.183'}, : 100%|\u001b[34m█\u001b[0m| 1/1 [00:00<0\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "rtf_avg: -0.183: 100%|\u001b[34m███████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:00<00:00,  5.29it/s]\u001b[0m\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|\u001b[31m████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 1/1 [00:02<00:00,  2.62s/it]\u001b[0m\u001b[A\u001b[A\n",
      "\n",
      "rtf_avg: 0.051, time_speech:  51.663, time_escape: 2.614: 100%|\u001b[31m██████████████████████████\u001b[0m| 1/1 [00:02<00:00,  2.62s/it]\u001b[0m\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': '2speakers_example', 'text': '嗯，那么今天我们就简单的进行一下那个新生招聘的嗯讨论吧。因为现在不是好像就新生到校嘛，然后我们社团呢也需要招聘一些新的社员，然后就今天就大概就讨论一下嗯怎么招聘的内容吧。嗯，我们就首先想一下那个招聘的地点在哪里吧。嗯地点的话我们现在可以有三个选择。嗯，第一个的话我们可以选择在操场，因为那儿嗯学生流动量也挺大的。操场的话这这段时间太热了，我怕那个人流量有点少。嗯，那我们还可以有第二个选择呀。嗯，我们可以在图书馆楼下那里有一块可以遮阴的地方哦，图书馆我觉得应该还可以吧。', 'timestamp': [[390, 630], [630, 790], [790, 930], [930, 1070], [1070, 1290], [1290, 1430], [1430, 1670], [1670, 1910], [2010, 2210], [2210, 2390], [2390, 2530], [2530, 2690], [2690, 2930], [2950, 3050], [3050, 3270], [3270, 3470], [3470, 3710], [3750, 3990], [4010, 4250], [4330, 4550], [4550, 4790], [4850, 5090], [5510, 5750], [6190, 6410], [6410, 6650], [6650, 6890], [6910, 7010], [7010, 7190], [7190, 7350], [7350, 7530], [7530, 7650], [7650, 7890], [8370, 8610], [8610, 8730], [8730, 8890], [8890, 9090], [9090, 9330], [9350, 9510], [9510, 9750], [9810, 10050], [10350, 10530], [10530, 10650], [10650, 10730], [10730, 10870], [10870, 11070], [11070, 11250], [11250, 11390], [11390, 11590], [11590, 11730], [11730, 11890], [11890, 12070], [12070, 12270], [12270, 12430], [12430, 12550], [12550, 12790], [12790, 12950], [12950, 13190], [13210, 13450], [13950, 14110], [14110, 14350], [14350, 14590], [14610, 14770], [14770, 14950], [14950, 15190], [15210, 15370], [15370, 15550], [15550, 15770], [15770, 15970], [15970, 16190], [16190, 16330], [16330, 16570], [16930, 17170], [17250, 17410], [17410, 17550], [17550, 17750], [17750, 17990], [17990, 18230], [18270, 18410], [18410, 18650], [18650, 18890], [19250, 19490], [19570, 19670], [19670, 19790], [19790, 20030], [20070, 20210], [20210, 20450], [20550, 20770], [20770, 20870], [20870, 21010], [21010, 21170], [21170, 21410], [21610, 21830], [21830, 22010], [22010, 22210], [22210, 22370], [22370, 22610], [22610, 22790], [22790, 22970], [22970, 23050], [23050, 23505], [24370, 24590], [24590, 24750], [24750, 24950], [24950, 25050], [25050, 25230], [25230, 25310], [25310, 25430], [25430, 25650], [25650, 25890], [25970, 26110], [26110, 26210], [26210, 26370], [26370, 26530], [26530, 26730], [26730, 26950], [26950, 27190], [27610, 27850], [27910, 28010], [28010, 28130], [28130, 28270], [28270, 28370], [28370, 28550], [28550, 28630], [28630, 28730], [28730, 28850], [28850, 28950], [28950, 29130], [29130, 29370], [29410, 29650], [30310, 30550], [30570, 30810], [30970, 31110], [31110, 31350], [31350, 31590], [31590, 31945], [32620, 32860], [33020, 33240], [33240, 33440], [33440, 33580], [33580, 33700], [33700, 33900], [33900, 34020], [34020, 34240], [34240, 34480], [34480, 34720], [34920, 35160], [35200, 35440], [35460, 35560], [35560, 35800], [36340, 36580], [36720, 36880], [36880, 37100], [37100, 37240], [37240, 37480], [37480, 37720], [37720, 37960], [38020, 38220], [38220, 38380], [38380, 38620], [39100, 39260], [39260, 39400], [39400, 39500], [39500, 39680], [39680, 39920], [40020, 40160], [40160, 40340], [40340, 40579], [41060, 41300], [41380, 41560], [41560, 41660], [41660, 41780], [41780, 42020], [42020, 42100], [42100, 42180], [42180, 42280], [42280, 42380], [42380, 42460], [42460, 42600], [42600, 42800], [42800, 43020], [43020, 43260], [43640, 43880], [44320, 44460], [44460, 44600], [44600, 44700], [44700, 44880], [44880, 45120], [45220, 45360], [45360, 45540], [45540, 45740], [45740, 45900], [45900, 46140], [46560, 46740], [46740, 46860], [46860, 47000], [47000, 47100], [47100, 47340], [47400, 47500], [47500, 47600], [47600, 47740], [47740, 47920], [47920, 48060], [48060, 48160], [48160, 48400], [48820, 49060], [49220, 49360], [49360, 49600], [49600, 49840], [49940, 50100], [50100, 50260], [50260, 50400], [50400, 50500], [50500, 50640], [50640, 50820], [50820, 51060], [51100, 51220], [51220, 51485]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "convert_model_name= \"iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\"\n",
    "snapshot_download(convert_model_name)\n",
    "\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model=convert_model_name, model_revision=\"v2.0.5\")\n",
    "\n",
    "rec_result = inference_pipeline('2speakers_example.wav')\n",
    "print(rec_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab131b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
